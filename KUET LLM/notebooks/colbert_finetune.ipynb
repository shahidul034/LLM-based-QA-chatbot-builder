{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the history and evolution of KUET?</td>\n",
       "      <td>Khulna University of Engineering &amp; Technology ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where is the KUET campus located, and what sur...</td>\n",
       "      <td>The KUET campus is situated at Fulbarigate, ap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Prompt  \\\n",
       "0         What is the history and evolution of KUET?   \n",
       "1  Where is the KUET campus located, and what sur...   \n",
       "\n",
       "                                               Reply  \n",
       "0  Khulna University of Engineering & Technology ...  \n",
       "1  The KUET campus is situated at Fulbarigate, ap...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_location = r\"/home/sdm/Desktop/shakib/KUET LLM/data/dataset_shakibV2.xlsx\" ## replace here\n",
    "data_df=pd.read_excel( data_location )\n",
    "data_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs=[]\n",
    "for x,y in zip(data_df['Prompt'],data_df['Reply']):\n",
    "    pairs.append((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sdm/Desktop/shakib/KUET LLM/data/rag4_dhiman.docx',\n",
       " '/home/sdm/Desktop/shakib/KUET LLM/data/rag2V3_2k20.docx',\n",
       " '/home/sdm/Desktop/shakib/KUET LLM/data/rag1_sadia_omar.docx']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "directory_path = r'/home/sdm/Desktop/shakib/KUET LLM/data/'\n",
    "file_pattern = '*.docx'  \n",
    "file_paths = glob.glob(directory_path + file_pattern)\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doc=[]\n",
    "for x in file_paths:\n",
    "    loader = Docx2txtLoader(x)\n",
    "    documents=loader.load()\n",
    "    # print(((documents)[0]).page_content)\n",
    "    all_doc.append(str(documents[0].page_content))\n",
    "docs='\\n\\n'.join(all_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Hard Negative SimpleMiner dense embedding model BAAI/bge-small-en-v1.5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d020339d6741118726dbb12adc215e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3b8af0b142842389d813c216d3eaf2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c252c63b966240fd8cd113f1e5e31585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92a34e1bb104060807dea6f35c31663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae94dcdf5f74d8589058168ce980962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951b15fd32984304b5bff44740962569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd833ed7e9f4157bd16a0482351c571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.onnx:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322486ff63ad4d05a320709f804ac10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1284f9f757c4df7800eb45e5e741744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b573ad41dfe74d23aee4ec0a49f96d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3421b9b147614172b3caaf1f822f4156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea18622f2cb4c04bafae5000747ae67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df59365121442bb8cab750a90a7ec6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c1fcdde8b545aa935ad23d2c1089b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building hard negative index for 592 documents...\n",
      "All documents embedded, now adding to index...\n",
      "save_index set to False, skipping saving hard negative index\n",
      "Hard negative index generated\n",
      "#> Starting...\n",
      "nranks = 1 \t num_gpus = 1 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"load_index_with_mmap\": false,\n",
      "    \"index_path\": null,\n",
      "    \"index_bsize\": 64,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 20,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 32,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 5e-6,\n",
      "    \"maxsteps\": 500000,\n",
      "    \"save_every\": 14,\n",
      "    \"warmup\": 14,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 2,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": \"FineTunedColBERT_rag\",\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 256,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"colbert-ir\\/colbertv2.0\",\n",
      "    \"triples\": \"data\\/triples.train.colbert.jsonl\",\n",
      "    \"collection\": \"data\\/corpus.train.colbert.tsv\",\n",
      "    \"queries\": \"data\\/queries.train.colbert.tsv\",\n",
      "    \"index_name\": null,\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \".ragatouille\\/\",\n",
      "    \"experiment\": \"colbert\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-03\\/23\\/12.38.48\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 1,\n",
      "    \"avoid_fork_if_possible\": false\n",
      "}\n",
      "Using config.bsize = 32 (per process) and config.accumsteps = 1\n",
      "[Mar 23, 12:48:58] #> Loading the queries from data/queries.train.colbert.tsv ...\n",
      "[Mar 23, 12:48:58] #> Got 454 queries. All QIDs are unique.\n",
      "\n",
      "[Mar 23, 12:48:58] #> Loading collection...\n",
      "0M \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sdm/anaconda3/envs/llmtesting/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sdm/anaconda3/envs/llmtesting/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sdm/anaconda3/envs/llmtesting/lib/python3.9/site-packages/colbert/infra/launcher.py\", line 134, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "  File \"/home/sdm/anaconda3/envs/llmtesting/lib/python3.9/site-packages/colbert/training/training.py\", line 55, in train\n",
      "    colbert = torch.nn.parallel.DistributedDataParallel(colbert, device_ids=[config.rank],\n",
      "  File \"/home/sdm/anaconda3/envs/llmtesting/lib/python3.9/site-packages/torch/nn/parallel/distributed.py\", line 795, in __init__\n",
      "    _verify_param_shape_across_processes(self.process_group, parameters)\n",
      "  File \"/home/sdm/anaconda3/envs/llmtesting/lib/python3.9/site-packages/torch/distributed/utils.py\", line 265, in _verify_param_shape_across_processes\n",
      "    return dist._verify_params_across_processes(process_group, tensors, logger)\n",
      "torch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/NCCLUtils.hpp:219, invalid argument, NCCL version 2.14.3\n",
      "ncclInvalidArgument: Invalid value for an argument.\n",
      "Last error:\n",
      "Invalid config blocking attribute value -2147483648\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = RAGTrainer(model_name = \"FineTunedColBERT_rag\",\n",
    "        pretrained_model_name = \"colbert-ir/colbertv2.0\") # In this example, we run fine-tuning\n",
    "\n",
    "# This step handles all the data processing, check the examples for more details!\n",
    "trainer.prepare_training_data(raw_data=pairs,\n",
    "                                data_out_path=\"./data/\",\n",
    "                                all_documents=docs)\n",
    "\n",
    "trainer.train(batch_size=32) # Train with the default hyperparams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmtesting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
